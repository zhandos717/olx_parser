import time
from pkg.parser import get_all_pages, _parse_links, _parse_item_page
from pkg.utils import _json_save, _get_prices


def main():
    print("\nüì¶ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ OLX Parser!")
    query = input("üîç –í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: ").strip()
    if not query:
        print("‚ùå –ó–∞–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.")
        return

    start_time = time.time()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    pages = get_all_pages(query=query, country='KZ', currency='KZT', city='astana', condition='all')
    print(f"\nüìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(pages)}")

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ —Å –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    all_links = []
    for soup in pages:
        all_links.extend(_parse_links(soup))
    print(f"üîó –ù–∞–π–¥–µ–Ω–æ –≤—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(all_links)}")

    # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
    print("\n‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–±—ä—è–≤–ª–µ–Ω–∏–π...")
    all_data = []
    for link in all_links:
        item = _parse_item_page(link)
        if item:
            all_data.append(item)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    _json_save(all_data)

    # –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞
    prices = _get_prices(pages[0]) if pages else []
    avg_price = int(sum(prices) / len(prices)) if prices else 0
    print(f"\nüí∞ –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ (–ø–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ): {avg_price} ‚Ç∏")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    elapsed = time.time() - start_time
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f} —Å–µ–∫.")
    print(f"üìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/data.json\n")


if __name__ == "__main__":
    main()
