import re
import json
import requests
from pathlib import Path
from typing import Optional, List, Dict
from bs4 import BeautifulSoup
from pkg.config import headers, MAIN_PAGE_PRICES_CLASS


def _fetch_url(url: str) -> Optional[BeautifulSoup]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É URL –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç BeautifulSoup.
    """
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        return BeautifulSoup(response.text, 'lxml')
    except requests.RequestException as e:
        print(f"[–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞] {url}: {e}")
        return None



def _get_prices(soup: BeautifulSoup) -> List[int]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö —Ü–µ–Ω —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ–±—ä—è–≤–ª–µ–Ω–∏–π.
    """
    prices = soup.find_all("p", class_=MAIN_PAGE_PRICES_CLASS)
    price_list = []

    for price_tag in prices:
        cleaned = re.sub(r"[^\d\s]", "", price_tag.text).replace(" ", "")
        match = re.match(r"(\d+)", cleaned)
        if match:
            price_list.append(int(match.group(1)))

    return price_list


def _json_save(data: List[Dict[str, str]], filename: str = "data.json") -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON-—Ñ–∞–π–ª –≤ –ø–∞–ø–∫–µ `data/`.

    Parameters
    ----------
    data : List[Dict[str, str]]
        –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.
    filename : str
        –ò–º—è —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 'data.json').
    """
    output_dir = Path("data")
    output_dir.mkdir(parents=True, exist_ok=True)

    file_path = output_dir / filename

    try:
        with file_path.open("w", encoding="utf-8") as file:
            json.dump(data, file, indent=4, ensure_ascii=False)
        print(f"üìÅ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {file_path.resolve()}")
    except IOError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
